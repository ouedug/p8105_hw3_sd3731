---
title: "hw3_sd3731"
author: "Susie Dong"
date: "2023-10-15"
output: github_document
---

Load libraries

```{r loading libraries, message=FALSE}
knitr::opts_chunk$set(
	echo = TRUE,
	message = FALSE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)

library(tidyverse)
library(p8105.datasets)
```

# Problem 1

```{r loading dataset}
data("instacart")
```
## Data Description

The dataset called `instacart` comprises a total of `r nrow(instacart)` data points across `r ncol(instacart)` different attributes. 

The dataset consists of rows representing individual products in Instacart orders. It includes variables with details like product ID, name, order date, and a flag indicating if the product was reordered by the user. Additionally, the dataset contains user IDs and order IDs. Furthermore, it provides information about the product's aisle (e.g., yogurt) and department (e.g., dairy eggs).

Key variables:  

  - `order_id`: order identifier

  - `product_id`: product identifier

  - `add_to_cart_order`: order in which each product was added to cart 

  - `reordered`: 1 = this prodcut has been ordered by this user in the past, 0 = otherwise

  - `user_id`: customer identifier

  - `eval_set`: which evaluation set this order belongs in (Note that the data for use in this class is exclusively from the “train” eval_set)

  - `order_number`: the order sequence number for this user (1=first, n=nth)

  - `order_dow`: the day of the week on which the order was placed

  - `order_hour_of_day`: the hour of the day on which the order was placed

  - `days_since_prior_order`: days since the last order, capped at 30, NA if order_number=1
    
  - `product_name`: name of the product

  - `aisle_id`: aisle identifier

  - `department_id`: department identifier

  - `aisle`: the name of the aisle

  - `department`: the name of the department
  
## Answers

1.  How many aisles are there, and which aisles are the most items ordered from?

```{r}
instacart |> 
  group_by(aisle) |> 
  summarize(n_obs = n()) |> 
  arrange(desc(n_obs))
```

  There are `r length(unique(pull(instacart, aisle_id)))` aisles in total. 
  The aisle with id `r instacart |> group_by(aisle_id) |> summarize(n_orders = n()) |> mutate(max_order = max(n_orders)) |> filter(n_orders == max_order) |> pull(aisle_id)` are the aisle with most order items.
  
  To sum up, out of the 134 available aisles, the aisle containing fresh vegetables is the one from which the most items are ordered.

2. Make a plot that shows the number of items ordered in each aisle, limiting this to aisles with more than 10000 items ordered. Arrange aisles sensibly, and organize your plot so others can read it.

```{r}
instacart |> 
  group_by(aisle) |> 
  summarize(n_obs = n()) |> 
  filter(n_obs > 10000) |> 
  mutate(aisle = fct_reorder(aisle, n_obs)) |> 
  ggplot(aes(x = aisle, y = n_obs)) +
  geom_point() +
  labs(y = "count", title = "Number of products ordered in aisle") +
  theme(axis.text.x = element_text(angle = 60, hjust = 1))

```

Comments:
There are `r nrow(slice1)` aisles where more than 10,000 items have been ordered.
Among them, 2 aisles have witnessed orders of over 120,000 items.
For 3 aisles, the number of ordered items falls within the range of 40,000 to 80,000.
The remaining aisles have fewer than 40,000 ordered items.

3. Make a table showing the three most popular items in each of the aisles “baking ingredients”, “dog food care”, and “packaged vegetables fruits”. Include the number of times each item is ordered in your table.

```{r}
instacart |> 
  filter(
    aisle == "baking ingredients" |
    aisle == "dog food care" | 
    aisle == "packaged vegetables fruits") |> 
  group_by(aisle, product_name) |> 
  summarize(n_order = n()) |> 
  mutate(
    n_order_rank = min_rank(desc(n_order))) |> 
  arrange(desc(n_order)) |> 
  filter(n_order_rank <= 3) |> 
  knitr::kable()
```

Conclusion:
 The three most popular items in the `baking ingredients` aisle are identified by the IDs 23537, 23405, and 49533. 
 In the `dog food care` aisle, the top three popular items are labeled with IDs 722, 23329, and 17471. 
 As for the `packaged vegetables fruits` aisle, the top three popular items are represented by IDs 21903, 27966, and 39275.

4. Make a table showing the mean hour of the day at which Pink Lady Apples and Coffee Ice Cream are ordered on each day of the week; format this table for human readers (i.e. produce a 2 x 7 table).

```{r}
instacart |> 
  filter(
    product_name == "Pink Lady Apples"|
    product_name == "Coffee Ice Cream") |> 
  group_by(product_name, order_dow) |> 
  summarize(mean_hour = mean(order_hour_of_day)) |> 
  pivot_wider(
    names_from = product_name,
    values_from = mean_hour) |> 
  knitr::kable(digits = 2)

```

Conclusion:
The typical time for ordering Coffee Ice Cream falls between 12 and 16 during the week, while the typical ordering hours for Pink Lady Apples are from 11 to 15.

# Problem 2

## Load and clean the dataset.

```{r}
data("brfss_smart2010")

brfss <-
  brfss_smart2010 |> 
  janitor::clean_names() |> 
  rename(state = locationabbr,
         county = locationdesc) |> 
  filter(topic == "Overall Health"& 
           response %in% c("Excellent", "Very good", "Good", "Fair", "Poor"))|> 
  mutate(
    response = 
      factor(response, 
             levels = c("Poor", "Fair", "Good", "Very good", "Excellent")),
    county = substring(county, 6))

```

The provided code loads and processes the "brfss_smart2010" dataset. The resulting cleaned dataset, named "brfss," includes `r nrow(brfss)` data points and `r ncol(brfss)` attributes, specifically centered on the subject of "Overall Health," encompassing responses ranging from "Poor" to "Excellent."

## Answers

1. In 2002, which states were observed at 7 or more locations? What about in 2010?

```{r}
brfss |> 
  filter(year == 2002) |> 
  group_by(state) |> 
  summarize(
    n_states = 
      n_distinct(county)) |> 
  filter(n_states >= 7) |> 
  knitr::kable()
```

In 2002, 6 states (CT, FL, MA, NC, NJ, and PA states) in table above were observed at 7 or more locations.

```{r}
brfss |> 
  filter(year == 2010) |> 
  group_by(state) |> 
  summarize(
    n_states = 
      n_distinct(county)) |> 
  filter(n_states >= 7) |> 
  knitr::kable()
```

 In 2010, 14 states (CA, CO, FL, MA, MD, NC, NE, NJ, NY, OH, PA, SC, TX, and WA) in table above were observed at 7 or more locations.

2. Construct a dataset that is limited to `Excellent` responses, and contains, year, state, and a variable that averages the `data_value` across locations within a state. 

Make a “spaghetti” plot of this average value over time within a state (that is, make a plot showing a line for each state across years – the `geom_line` geometry and `group` aesthetic will help).

```{r}
brfss |> 
  filter(response == "Excellent") |> 
  group_by(state, year) |> 
  mutate(
    mean_data_value = mean(data_value)) |> 
  select(year, state, mean_data_value) |> 
  unique() |> 
  ggplot(aes(x = year, y = mean_data_value, color = state)) +
  geom_line() +
  labs(y = "crude prevalence (%)", 
       title = "Mean crude prevalence across year for each state") +
  theme(legend.position = "bottom")
```

```{r}
brfss |> 
  filter((year == 2006 | year == 2010) & state == "NY") |> 
  ggplot(aes(x = response, y = data_value, color = response)) +
  geom_boxplot() +
  facet_grid(. ~ year) + 
  labs(y = "crude prevalence (%)", title = "Crude prevalence vs. responses in NY State") +
  theme(axis.text.x = element_text(angle = 60, hjust = 1))
```

Conclusion:
The "spaghetti" plot displays the average crude prevalence of the "Excellent" response over time, with each line representing a different state. The plot reveals a relatively consistent crude prevalence from 2002 to 2010, indicating no substantial increase or decrease in this data value during that period.

The boxplot illustrates the crude prevalence, referred to as `data_value`, for various responses ranging from "Poor" to "Excellent" in New York State for the years 2006 and 2010. In both years, the "Poor" response has the lowest crude prevalence, indicating fewer people reported their health as "Poor." The majority of respondents chose "Very good" or "Good" in both years. Notably, in 2010, a larger proportion of respondents selected "Very good" compared to 2006, suggesting a shift in health evaluations over time.

# Problem 3

## Data Manipulation

Load, tidy, merge, and otherwise organize the data sets. Your final dataset should include all originally observed variables; exclude participants less than 21 years of age, and those with missing demographic data; and encode data with reasonable variable classes (i.e. not numeric, and using factors with the ordering of tables and plots in mind).

```{r}
accel <- 
  read_csv("data/nhanes_accel.csv") |> 
  janitor::clean_names() |> 
  pivot_longer(
    min1:min1440,
    names_to = "min",
    values_to = "accel_value",
    names_prefix = "min") |> 
  mutate(
    min = as.numeric(min)
  )

covar <- 
  read_csv("data/nhanes_covar.csv", skip = 4) |> 
  janitor::clean_names() |> 
  filter(age >= 21) |> 
  mutate(
    sex = case_match(
      sex,
      1 ~ "male",
      2 ~ "female"),
    sex = factor(
      sex, 
      levels = c("male", "female"))) |> 
  drop_na()

nhanes_df <-
  inner_join(covar, accel)
```

The processed dataset called `nhanes_df` contains `r nrow(nhanes_df)` data entries and `r ncol(nhanes_df)` attributes. It encompasses MIMS values measured in minutes over a 24-hour period and also stores additional details like sequence number, age, gender, BMI, and education level.

## Answers

1. Produce a reader-friendly table for the number of men and women in each education category, and create a visualization of the age distributions for men and women in each education category. Comment on these items.


```{r count number of men and women by education category}
nhanes_df |> 
  select(seqn, sex, age, education) |> 
  unique() |> 
  group_by(sex, education) |> 
  summarize(count = n()) |> 
  pivot_wider(
    names_from = sex,
    values_from = count) |> 
  knitr::kable()
```

Comments:
For male participants, the distribution of education levels is as follows: More than high school > High school equivalent > Less than high school.
Among female participants, the distribution of education levels is: More than high school > Less than high school > High school equivalent.

```{r boxplot for age distribution}
nhanes_df |> 
  select(seqn, sex, age, education) |> 
  unique() |> 
  ggplot(aes(x = sex, y = age, color = sex)) +
  geom_boxplot() +
  labs(title = "Age distributions by education category for men and women") +
  facet_grid(. ~ education)
```

Comments:
The boxplot depicts age distributions for men and women within different education categories. Notably, individuals of both genders with education levels exceeding high school have the lowest median age compared to those in other education categories. Among females, those with a high school education exhibit the highest median age, while among males, individuals with education levels below high school have the highest median age. Furthermore, females with a high school education tend to be older than males with similar educational backgrounds.

2. Traditional analyses of accelerometer data focus on the total activity over the day. Using your tidied dataset, aggregate across minutes to create a total activity variable for each participant. Plot these total activities (y-axis) against age (x-axis); your plot should compare men to women and have separate panels for each education level. Include a trend line or a smooth to illustrate differences. Comment on your plot.

```{r total MIMS value vs. age}
nhanes_df |> 
  group_by(seqn, sex, age, education) |> 
  summarize(accel_sum = sum(accel_value)) |> 
  ggplot(aes(x = age, y = accel_sum, color = sex)) +
  geom_point() +
  geom_smooth(se = FALSE) +
  facet_grid(. ~ education) +
  labs(y = "total MIMS value", title = "Total MIMS value vs. age") +
  theme(legend.position = "bottom")
```

Comments:
The amount of activity exhibited by participants typically decreases as they grow older, with occasional instances of 1-2 peaks at specific ages. The range of fluctuations in activity among male participants is narrower compared to that among female participants.

3. Accelerometer data allows the inspection activity over the course of the day. Make a three-panel plot that shows the 24-hour activity time courses for each education level and use color to indicate sex. Describe in words any patterns or conclusions you can make based on this graph; including smooth trends may help identify differences.

```{r}
nhanes_df |> 
  group_by(min, sex, education) |> 
  mutate(
    mean_accel = mean(accel_value),
    min = as.numeric(min)) |> 
  select(sex, education, min, mean_accel) |> 
  unique() |> 
  ggplot(aes(x = min, y = mean_accel, color = sex)) +
  geom_line() +
  facet_grid(education ~ .) +
  labs(y = "mean MIMS value", title = "Mean MIMS values in 24-hour activity time courses") +
  theme(legend.position = "bottom")
```

Conclusion:
The plot displays the average MIMS (Minutes in Motion Sensor) values over a 24-hour activity period for individuals of different education levels, separated by gender. The activity data is measured on a minute-by-minute basis, ranging from 1 to 1440 minutes in a day.

The plot indicates that the average MIMS values generally decline during the first 5 hours (300 minutes), followed by an increase over the next 4 hours (approximately 250 minutes). Subsequently, in the following 6 hours, participants in education categories 1 and 2 show a gradual decline in MIMS activity, while those in education category 3 maintain a relatively stable level of activity. Finally, in the last 5 hours, the MIMS values decrease for all groups.

Notably, it's observed that the average MIMS value for females in education category 3 is slightly higher than that of their male counterparts.

